# ML Object Detection and Counting Challange
## @Author : Bilge Kaan GÃ¼rgen

## BaÅŸlamadan Ã–nce

---

- Verilen [**Github**](https://github.com/Stroma-Vision/machine-learning-challenge) reposunu incelendi.
- **640x640** pixel boyutunda **Test, Train, Val** olmak Ã¼zere **3 adet video** dosyasÄ± verildi.
- **COCO** formatÄ±nda Label iÅŸlemi yapÄ±lmÄ±ÅŸ.
- **Bolt ,Nut** olarak 2 Class tespiti ve bunlarÄ±n sayÄ±lmasÄ± istenmektedir.

Ã–rnek verilmiÅŸ Bounding Box ile Object Detection yapÄ±lmÄ±ÅŸ projenin aslÄ±nda bizden istenen gÃ¶rÃ¼ntÃ¼sÃ¼

![https://github.com/Stroma-Vision/machine-learning-challenge/blob/main/sample.gif?raw=true](https://github.com/Stroma-Vision/machine-learning-challenge/blob/main/sample.gif?raw=true)

**JSON formatÄ±nda verilen Ã¶rnek annotation dosyasÄ±**

---

```json
{
    "info": {
        "description": "Nuts and Bolts Dataset",
        "url": "",
        "version": "1.0",
        "year": 2023,
        "contributor": "Dogukan",
        "date_created": "2023/01/18"
    },
    "licenses": [],
    "images": [
        {
            "file_name": "0000.jpg",
            "width": 640,
            "height": 640,
            "id": 1
        },
				.................
				{
            "file_name": "1799.jpg",
            "width": 640,
            "height": 640,
            "id": 1800
        }
    ]
```

# 1-Preprocess

---

Bize Verilen videolardan Ã¶rneÄŸin 60 Saniyelik 30FPS Videoâ€™nun 1800 Frameâ€™den oluÅŸtuÄŸu bilinmektedir. Bunun sonucunda alacaÄŸÄ±mÄ±z video dosyasÄ±na ait `JSON Annotation` dosyasÄ±nda da o kadar `id` sayÄ±sÄ±nda olmasÄ± gerekiyor. 

Bunun iÃ§in Videoâ€™yu Frameâ€™lerine bÃ¶lerek Ã§Ä±kartan Python Kodu yazdÄ±m. `Extractor.py`

### Output dosyalarÄ±nÄ±n olmasÄ± gereken gÃ¶rÃ¼ntÃ¼sÃ¼

![Untitled](readme_media/Untitled.png)

### **AdÄ±mlar**

1. Bize verilen verisetini [buradan](https://github.com/Stroma-Vision/machine-learning-challenge/releases) indirmeliyiz.
2. Preprocess KlasÃ¶rÃ¼nde ki `extractor.py` ile bu verisetinde ki video dosyasÄ±nÄ± frameâ€™lere ayÄ±rÄ±yoruz. 
3. AyrÄ±ÅŸmÄ±ÅŸ frame klasÃ¶rÃ¼ iÃ§erisine bize verilen dataset [buradan](https://github.com/Stroma-Vision/machine-learning-challenge/releases) iÃ§erisinde hangi video frameâ€™lere  ayrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ ise ona ait JSON annotation dosyasÄ± da o klasÃ¶re kopyalanmalÄ±dÄ±r.
4. Bu aÅŸamalardan sonra gÃ¶rÃ¼ntÃ¼sÃ¼ [buradaki](https://github.com/bkaan99/challange/blob/master/readme_media/Untitled.png) gibi olmalÄ±.
5. AyÄ±rÄ±lmÄ±ÅŸ Frameleri [ROBOFLOW](https://app.roboflow.com/) sitesine yÃ¼klÃ¼yoruz. YÃ¼kleme aÅŸamalarÄ±nda sadece test, train, valid bÃ¶lme iÅŸlemini yapmanÄ±z yeterlidir. [AdÄ±m AdÄ±m YÃ¼kleme aÅŸamalarÄ±](https://roboflow.com/convert/coco-json-to-yolo-darknet-txt)
    
    ![Untitled](readme_media/Untitled%201.png)
    
6. YÃ¼kledikten sonra Roboflow Ã¼zerinde verisetini yolov7 formatÄ±nda Export etmeliyiz. 
7. Export aÅŸamasÄ±nda bilgisayarÄ±ma indirmeden download code ile Colab iÃ§erisine dahil edebiliriz.

OluÅŸan verisetine bu [Link](https://app.roboflow.com/bilge-kaan-grgen-j9nkx/obj-2/2)â€™ den ulaÅŸabilirsiniz. 

# 2- Train

---

`EÄŸitim Yolov7 kullanÄ±larak yapÄ±lacaktÄ±r.` [Yolov7](https://github.com/wongkinyiu/yolov7)

Training aÅŸamasÄ±nÄ± `Training` klasÃ¶rÃ¼ iÃ§erisinde ki notebook dosyasÄ±ndan yapÄ±yoruz. Bu aÅŸamayÄ± Google Colab Ã¼zerinde yapacaÄŸÄ±z.

### **AdÄ±mlar**

1. Colab Ã¼zerinde belirtilen notebook dosyasÄ±nÄ± aÃ§Ä±n. [Colab Training Notebook](https://colab.research.google.com/drive/1N1x6fRbfz6tga9kPmcIBTE8yS0EQNZ4x#scrollTo=6AGhNOSSHY4_)
2. Colab iÃ§erisinde belirtilen adÄ±mlarÄ± hÃ¼creleri Ã§alÄ±ÅŸtÄ±rarak ilerleyin.
3. HiÃ§bir deÄŸiÅŸiklik yapmadan (batch size, epoch sayÄ±sÄ±) Ã§alÄ±ÅŸtÄ±rarak eÄŸitebilirsiniz. Overfit (AÅŸÄ±rÄ± Ã–ÄŸrenme) durumunda `yolov7.yaml` dosyasÄ±nda ki learning rate deÄŸerini deÄŸiÅŸtirerek ilerleyebilirsiniz.
4. EÄŸitim sonucunda model dosyalarÄ±nÄ±z Colab iÃ§erisindeki `runs/train/weights` â€˜de kaydedilmektedir. Biz en iyi sonucu olan model dosyasÄ±nÄ± yani best.pt dosyasÄ±nÄ± kullanacaÄŸÄ±z..
5. `best.pt` dosyanÄ±zÄ± Drive iÃ§erisine taÅŸÄ±mayÄ± unutmayÄ±n. Ã‡Ã¼nkÃ¼ bu dosyayÄ± predict aÅŸamasÄ±nda kullanmamÄ±z gerekmektedir. 

### HÃ¼cre AÃ§Ä±klamalarÄ±

---

```python
!nvidia-smi
```

**`nvidia-smi`** (NVIDIA System Management Interface) bir komut satÄ±rÄ± aracÄ±dÄ±r ve NVIDIA GPU'larÄ±nÄ±n sistemle ilgili bilgilerini gÃ¶rÃ¼ntÃ¼lemek iÃ§in kullanÄ±lÄ±r. Bu araÃ§, GPU bellek kullanÄ±mÄ±nÄ±, iÅŸlemci kullanÄ±mÄ±nÄ±, sÄ±caklÄ±ÄŸÄ±, saat hÄ±zÄ±nÄ±, gÃ¼Ã§ tÃ¼ketimini ve diÄŸer Ã§eÅŸitli performans Ã¶lÃ§Ã¼mlerini gÃ¶rÃ¼ntÃ¼lemeyi saÄŸlar.

```python
!git clone https://github.com/SkalskiP/yolov7.git
%cd yolov7
!git checkout fix/problems_associated_with_the_latest_versions_of_pytorch_and_numpy
!pip install -r requirements.txt
```

Yolov7 reposu indirilir ve requirements.txt dosyasÄ±nda ki kÃ¼tÃ¼phaneler yÃ¼klenir.

```python
!pip install roboflow 

from roboflow import Roboflow
rf = Roboflow(api_key="x5tKxqHm8Of46UZ2y5eV")
project = rf.workspace("bilge-kaan-grgen-j9nkx").project("obj-2")
dataset = project.version(2).download("yolov7")
```

Roboflow API'sini kullanarak belirli bir Roboflow projesindeki veri kÃ¼mesini indiriyor.

```python
%cd /content/yolov7
!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt
```

Yolov7 modelinin eÄŸitiminde kullanÄ±labilecek Ã¶nceden eÄŸitilmiÅŸ bir aÄŸÄ±rlÄ±k dosyasÄ±nÄ± indirir.

```python
%cd /content/yolov7
!python train.py --batch 16 --epochs 55 --data {dataset.location}/data.yaml --weights 'yolov7_training.pt' --device 0
```

Bu kod, YOLOv7 modeli iÃ§in eÄŸitim yapmak Ã¼zere **`train.py`** dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r.

- **`-batch 16`** parametresi, her bir eÄŸitim adÄ±mÄ±nda kullanÄ±lacak olan gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±nÄ± belirtir.
- **`-epochs 55`** parametresi, toplamda kaÃ§ epoch (bir epoch, tÃ¼m eÄŸitim verilerinin bir kez geÃ§tiÄŸi durumu ifade eder) eÄŸitim yapÄ±lacaÄŸÄ±nÄ± belirtir.
- **`-data {dataset.location}/data.yaml`** parametresi, veri setinin konumunu belirten YAML dosyasÄ±nÄ±n konumunu belirtir.
- **`-weights 'yolov7_training.pt'`** parametresi, Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klarÄ±n konumunu belirtir.
- **`-device 0`** parametresi, kullanÄ±lacak olan GPU numarasÄ±nÄ± belirtir.

EÄŸitim aÅŸamasÄ±na ait gÃ¶rÃ¼ntÃ¼.

```python
.............
.............
Epoch   gpu_mem       box       obj       cls     total    labels  img_size
     53/54     12.7G   0.03008  0.004752   0.00143   0.03626        17       640: 100% 71/71 [01:03<00:00,  1.11it/s]
               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 9/9 [00:05<00:00,  1.56it/s]
                 all         279         698       0.966       0.937       0.988       0.818

     Epoch   gpu_mem       box       obj       cls     total    labels  img_size
     54/54     12.7G   0.01908  0.004578 0.0009224   0.02458        27       640: 100% 71/71 [01:03<00:00,  1.11it/s]
               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 9/9 [00:07<00:00,  1.25it/s]
                 all         279         698       0.969       0.979       0.987       0.831
                bolt         279         570       0.984       0.965       0.992       0.863
                 nut         279         128       0.955       0.992       0.982         0.8
55 epochs completed in 1.108 hours.

Optimizer stripped from runs/train/exp/weights/last.pt, 74.8MB
Optimizer stripped from runs/train/exp/weights/best.pt, 74.8MB
```

```python
%load_ext tensorboard
%tensorboard --logdir /content/yolov7/runs/train
```

**`load_ext`**Tensorboard'u Colab'da kullanmamÄ±za olanak saÄŸlar. 

train klasÃ¶rÃ¼ altÄ±ndaki log dosyalarÄ±na eriÅŸmek iÃ§in **`logdir`** parametresi kullanÄ±lmÄ±ÅŸtÄ±r. Bu sayede, modelin eÄŸitimi sÄ±rasÄ±nda kaydedilen metrikleri ve gÃ¶rselleÅŸtirmeleri gÃ¶zlemleyebiliriz.

![Untitled](readme_media/Untitled%202.png)

```python
from google.colab import drive
drive.mount('/content/drive')
```

Google drive baÄŸlantÄ±mÄ±zÄ± yapÄ±yoruz. 

### TensorBoard Ã‡Ä±ktÄ±larÄ± & mAP, Precision, Recall

---

Tensorboard'daki "map" deÄŸeri, modelin ortalama hassasiyet deÄŸerini (mAP) ifade eder. Bu deÄŸer, modelin sÄ±nÄ±flandÄ±rma doÄŸruluÄŸunu Ã¶lÃ§mek iÃ§in kullanÄ±lÄ±r. mAP, tÃ¼m sÄ±nÄ±flarÄ±n hassasiyet deÄŸerlerinin ortalamasÄ±dÄ±r.

"map05:0.95" deÄŸeri, 0.5 ile 0.95 arasÄ±ndaki tÃ¼m eÅŸik deÄŸerleri iÃ§in ortalama hassasiyet deÄŸerini ifade eder. Bu deÄŸer, modelin daha geniÅŸ bir aralÄ±kta nasÄ±l performans gÃ¶sterdiÄŸini gÃ¶sterir.

Precision ve recall deÄŸerleri, modelin doÄŸruluÄŸunu daha ayrÄ±ntÄ±lÄ± bir ÅŸekilde analiz etmek iÃ§in kullanÄ±lan diÄŸer Ã¶lÃ§Ã¼mlerdir. Precision, modelin doÄŸru sÄ±nÄ±flandÄ±rÄ±lan nesnelerin sayÄ±sÄ±nÄ±n, toplam sÄ±nÄ±flandÄ±rÄ±lan nesnelerin sayÄ±sÄ±na oranÄ±nÄ± ifade eder. Recall ise, modelin doÄŸru sÄ±nÄ±flandÄ±rÄ±lan nesnelerin sayÄ±sÄ±nÄ±n, toplam gerÃ§ek nesne sayÄ±sÄ±na oranÄ±nÄ± ifade eder. Bu Ã¶lÃ§Ã¼mler, modelin hangi sÄ±nÄ±flarÄ±n daha iyi sÄ±nÄ±flandÄ±rÄ±ldÄ±ÄŸÄ±nÄ± ve hangi sÄ±nÄ±flarÄ±n daha kÃ¶tÃ¼ performans gÃ¶sterdiÄŸini belirlemeye yardÄ±mcÄ± olur.

### **Model Ã‡Ä±ktÄ± dosyasÄ±**

> `best.pt` file [drive link](https://drive.google.com/file/d/1vjdGoTi0UGOjXEuRv3W6EqY0UJVcbay6/view?usp=sharing)
> 

### Runtime HatasÄ± iÃ§in Ã§Ã¶zÃ¼m

Train komutunu Ã§alÄ±ÅŸtÄ±rÄ±rken bazen `RuntimeError: indices should be either on cpu or on the same device as the indexed tensor (cpu)` belirtilen runtime hatasÄ± alabiliyoruz. Bunun iÃ§in Ã§ok gÃ¼zel ve kolay bir Ã§Ã¶zÃ¼m yolu stackoverflowâ€™da anlatÄ±lmÄ±ÅŸ.  [Ã‡Ã¶zÃ¼m](https://stackoverflow.com/questions/74372636/indices-should-be-either-on-cpu-or-on-the-same-device-as-the-indexed-tensor)

# 3-Prediction

---

Model Ã§Ä±ktÄ±larÄ±mÄ±z aldÄ±ktan sonra objelerin saydÄ±rÄ±lmasÄ±, Bounding Boxâ€™lar iÃ§erisinde doÄŸruluk deÄŸerleri ve hangi obje olduÄŸunu gÃ¶stereceÄŸiz.

1. [Colab Prediction Notebook](https://colab.research.google.com/drive/1lW7p1Tw6SE8iW0mEsd42w5z_AfVp-ESg?usp=sharing) â€˜ linkinden Colab Notebookâ€™una ulaÅŸÄ±yoruz.
2. Colab iÃ§erisinde ki hÃ¼crelere ait adÄ±mlarÄ± takip ediyoruz.
3. AdÄ±mlardan drive baÄŸlama adÄ±mÄ±ndan sonra verilmiÅŸ drive linki Ã¼zerinden [Drive](https://drive.google.com/file/d/1vWEsg5wmFAy4PqPwugHecPzBAVgnpn0B/view?usp=sharing) yada [Prediction/**ObjectTracker**/](https://github.com/bkaan99/challange/tree/master/Prediction/ObjectTracker)  Dosya yolu iÃ§erisinde ki `pred.py` , `sort.py` , `requirements.txt` ve `requirements_gpu.txt` 4 adet dosyayÄ± Colab iÃ§erisinde oluÅŸan yolov7 klasÃ¶rÃ¼ iÃ§erisine atÄ±yoruz.
4. Takip ettikten sonra linkler Ã¼zerindeâ€™ki dosyalarÄ± kendi Colab dosya yollarÄ±nÄ±za indirerek prediction iÅŸlemlerinizi yapabilirsiniz.

# 4 - SonuÃ§

---

Colab ile Test notebook dosyasÄ± sonrasÄ± projede bizden istenen Ã§Ä±ktÄ±sÄ± verilmiÅŸtir.

[Final Result](https://drive.google.com/file/d/1BtbForG_GCb5M8spGb8GJssTC9nlwIwJ/view?usp=sharing)

## DetaylÄ± Rapor

---

[DetaylÄ± Rapor](https://www.notion.so/Milestone-ML-Challenge-41ac39fbf00e4cfbb13ed2021c5b0e07)

# TeÅŸekkÃ¼r

---

BildiÄŸimiz bilgileri pekiÅŸtirerek araÅŸtÄ±rma seviyemizi daha da artÄ±rdÄ±ÄŸÄ± iÃ§in bu challange adÄ±na Ã§ok memnunum. Herkese iyi Ã§alÄ±ÅŸmalar ğŸ™‚